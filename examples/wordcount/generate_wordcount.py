#!/usr/bin/env python3
"""
Python MapReduce ç¤ºä¾‹ - è¯é¢‘ç»Ÿè®¡
ç”¨äºŽHadoop Streamingçš„mapperå’Œreducer
"""

# mapper.py
mapper_code = '''#!/usr/bin/env python3
import sys
import re

# è¯»å–æ ‡å‡†è¾“å…¥
for line in sys.stdin:
    # ç§»é™¤è¡Œå°¾æ¢è¡Œç¬¦å¹¶è½¬æ¢ä¸ºå°å†™
    line = line.strip().lower()
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å•è¯ï¼Œåªä¿ç•™å­—æ¯å’Œæ•°å­—
    words = re.findall(r'\b[a-zA-Z]+\b', line)
    
    # è¾“å‡ºæ¯ä¸ªå•è¯å’Œè®¡æ•°1
    for word in words:
        if len(word) > 2:  # è¿‡æ»¤æŽ‰å¤ªçŸ­çš„å•è¯
            print(f"{word}\t1")
'''

# reducer.py
reducer_code = '''#!/usr/bin/env python3
import sys
from collections import defaultdict

# ä½¿ç”¨defaultdictæ¥å­˜å‚¨å•è¯è®¡æ•°
word_count = defaultdict(int)

# è¯»å–æ ‡å‡†è¾“å…¥
for line in sys.stdin:
    # ç§»é™¤è¡Œå°¾æ¢è¡Œç¬¦
    line = line.strip()
    
    # åˆ†å‰²å•è¯å’Œè®¡æ•°
    try:
        word, count = line.split('\t', 1)
        word_count[word] += int(count)
    except ValueError:
        # è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„è¡Œ
        continue

# æŒ‰è®¡æ•°é™åºæŽ’åºå¹¶è¾“å‡ºå‰100ä¸ªå•è¯
sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)

for word, count in sorted_words[:100]:
    print(f"{word}\t{count}")
'''

# åˆ›å»ºmapperæ–‡ä»¶
with open('mapper.py', 'w', encoding='utf-8') as f:
    f.write(mapper_code)

# åˆ›å»ºreduceræ–‡ä»¶
with open('reducer.py', 'w', encoding='utf-8') as f:
    f.write(reducer_code)

# è®¾ç½®æ‰§è¡Œæƒé™
import os
os.chmod('mapper.py', 0o755)
os.chmod('reducer.py', 0o755)

print("âœ… å·²åˆ›å»º mapper.py å’Œ reducer.py æ–‡ä»¶")
print("ðŸ“– ä½¿ç”¨æ–¹æ³•:")
print("1. å°†è¿™ä¸¤ä¸ªæ–‡ä»¶å¤åˆ¶åˆ°masterå®¹å™¨ä¸­:")
print("   docker cp mapper.py hadoop-master:/tmp/")
print("   docker cp reducer.py hadoop-master:/tmp/")
print("")
print("2. åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶:")
print("   echo 'Hello World Hello Hadoop This is a test file for word count' > input.txt")
print("   docker cp input.txt hadoop-master:/tmp/")
print("")
print("3. ä¸Šä¼ åˆ°HDFS:")
print("   docker-compose exec master hdfs dfs -mkdir -p /wordcount/input")
print("   docker-compose exec master hdfs dfs -put /tmp/input.txt /wordcount/input/")
print("")
print("4. æ‰§è¡ŒMapReduceä½œä¸š:")
print("   docker-compose exec master hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\")
print("       -files /tmp/mapper.py,/tmp/reducer.py \\")
print("       -mapper 'python3 /tmp/mapper.py' \\")
print("       -reducer 'python3 /tmp/reducer.py' \\")
print("       -input /wordcount/input \\")
print("       -output /wordcount/output")
print("")
print("5. æŸ¥çœ‹ç»“æžœ:")
print("   docker-compose exec master hdfs dfs -cat /wordcount/output/part-*")