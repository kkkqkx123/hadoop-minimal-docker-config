#!/usr/bin/env python3
"""
Java MapReduce æœ¬åœ°Mockæµ‹è¯•ç¤ºä¾‹
ç”¨äºåœ¨æœ¬åœ°ç¯å¢ƒä¸­æµ‹è¯•Java MapReduceé€»è¾‘
"""

import subprocess
import tempfile
import os
import json
import time
from pathlib import Path

def create_test_java_files():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„Javaæ–‡ä»¶"""
    
    # WordCount Mapper
    mapper_code = '''
import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper<Object, Text, Text, IntWritable> {
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    
    public void map(Object key, Text value, Context context) 
            throws IOException, InterruptedException {
        StringTokenizer itr = new StringTokenizer(value.toString());
        while (itr.hasMoreTokens()) {
            word.set(itr.nextToken());
            context.write(word, one);
        }
    }
}
'''

    # WordCount Reducer
    reducer_code = '''
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    private IntWritable result = new IntWritable();
    
    public void reduce(Text key, Iterable<IntWritable> values, Context context)
            throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        result.set(sum);
        context.write(key, result);
    }
}
'''

    # WordCount Driver
    driver_code = '''
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCountDriver {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(WordCountDriver.class);
        job.setMapperClass(WordCountMapper.class);
        job.setCombinerClass(WordCountReducer.class);
        job.setReducerClass(WordCountReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
'''

    # ä¿å­˜æ–‡ä»¶
    with open('WordCountMapper.java', 'w', encoding='utf-8') as f:
        f.write(mapper_code)
    
    with open('WordCountReducer.java', 'w', encoding='utf-8') as f:
        f.write(reducer_code)
    
    with open('WordCountDriver.java', 'w', encoding='utf-8') as f:
        f.write(driver_code)
    
    print("âœ… Javaæµ‹è¯•æ–‡ä»¶å·²åˆ›å»º")

def test_java_compilation():
    """æµ‹è¯•Javaç¼–è¯‘"""
    print("\nğŸ“‹ æµ‹è¯•Javaç¼–è¯‘...")
    
    # æ£€æŸ¥Javaç¯å¢ƒ
    try:
        result = subprocess.run(['java', '-version'], capture_output=True, text=True)
        if result.returncode != 0:
            print("âŒ Javaæœªå®‰è£…")
            return False
    except FileNotFoundError:
        print("âŒ Javaæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥Hadoopåº“
    hadoop_home = os.environ.get('HADOOP_HOME')
    if not hadoop_home:
        print("âš ï¸  HADOOP_HOMEæœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç¼–è¯‘æµ‹è¯•")
        return test_mock_compilation()
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    try:
        # å¤åˆ¶Javaæ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        for java_file in ['WordCountMapper.java', 'WordCountReducer.java', 'WordCountDriver.java']:
            if os.path.exists(java_file):
                subprocess.run(['cp', java_file, temp_dir], check=True)
        
        # ç¼–è¯‘Javaæ–‡ä»¶
        classpath = f"{hadoop_home}/share/hadoop/common/*:{hadoop_home}/share/hadoop/mapreduce/*:{hadoop_home}/share/hadoop/common/lib/*"
        
        compile_cmd = [
            'javac', '-cp', classpath,
            f'{temp_dir}/WordCountMapper.java',
            f'{temp_dir}/WordCountReducer.java',
            f'{temp_dir}/WordCountDriver.java'
        ]
        
        result = subprocess.run(compile_cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… Javaç¼–è¯‘æµ‹è¯•é€šè¿‡")
            return True
        else:
            print(f"âŒ Javaç¼–è¯‘å¤±è´¥: {result.stderr}")
            return False
    
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        import shutil
        shutil.rmtree(temp_dir)

def test_mock_compilation():
    """æ¨¡æ‹Ÿç¼–è¯‘æµ‹è¯•"""
    print("\nğŸ“‹ è¿è¡Œæ¨¡æ‹Ÿç¼–è¯‘æµ‹è¯•...")
    
    # æ£€æŸ¥Javaè¯­æ³•
    java_files = ['WordCountMapper.java', 'WordCountReducer.java', 'WordCountDriver.java']
    
    for java_file in java_files:
        if not os.path.exists(java_file):
            print(f"âŒ æ–‡ä»¶ {java_file} ä¸å­˜åœ¨")
            return False
        
        # ç®€å•çš„è¯­æ³•æ£€æŸ¥
        with open(java_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # æ£€æŸ¥åŸºæœ¬è¯­æ³•ç»“æ„
        if 'public class' not in content:
            print(f"âŒ {java_file} ç¼ºå°‘ç±»å®šä¹‰")
            return False
        
        if '{' not in content or '}' not in content:
            print(f"âŒ {java_file} æ‹¬å·ä¸åŒ¹é…")
            return False
        
        # æ£€æŸ¥importè¯­å¥
        if 'import' not in content:
            print(f"âš ï¸  {java_file} ç¼ºå°‘importè¯­å¥")
    
    print("âœ… æ¨¡æ‹Ÿç¼–è¯‘æµ‹è¯•é€šè¿‡")
    return True

def test_mapper_logic():
    """æµ‹è¯•mapperé€»è¾‘"""
    print("\nğŸ“‹ æµ‹è¯•mapperé€»è¾‘...")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = "hello world hello hadoop"
    expected_words = ['hello', 'world', 'hello', 'hadoop']
    
    # æ¨¡æ‹Ÿmapperå¤„ç†
    words = test_input.split()
    
    # éªŒè¯è¾“å‡ºæ ¼å¼
    mapper_output = []
    for word in words:
        mapper_output.append(f"{word}\t1")
    
    print("æ¨¡æ‹Ÿmapperè¾“å‡º:")
    for line in mapper_output:
        print(f"  {line}")
    
    # éªŒè¯ç»“æœ
    if len(mapper_output) == len(expected_words):
        print("âœ… Mapperé€»è¾‘æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âŒ Mapperé€»è¾‘æµ‹è¯•å¤±è´¥")
        return False

def test_reducer_logic():
    """æµ‹è¯•reduceré€»è¾‘"""
    print("\nğŸ“‹ æµ‹è¯•reduceré€»è¾‘...")
    
    # æ¨¡æ‹Ÿmapperè¾“å‡ºï¼ˆå·²æ’åºï¼‰
    mapper_output = [
        "hello\t1",
        "hello\t1", 
        "hadoop\t1",
        "world\t1"
    ]
    
    # æ¨¡æ‹Ÿreducerå¤„ç†
    word_counts = {}
    for line in mapper_output:
        word, count = line.split('\t')
        count = int(count)
        
        if word in word_counts:
            word_counts[word] += count
        else:
            word_counts[word] = count
    
    # ç”Ÿæˆreducerè¾“å‡º
    reducer_output = []
    for word, count in sorted(word_counts.items()):
        reducer_output.append(f"{word}\t{count}")
    
    print("æ¨¡æ‹Ÿreducerè¾“å‡º:")
    for line in reducer_output:
        print(f"  {line}")
    
    # éªŒè¯ç»“æœ
    expected = {"hello": 2, "hadoop": 1, "world": 1}
    if word_counts == expected:
        print("âœ… Reduceré€»è¾‘æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âŒ Reduceré€»è¾‘æµ‹è¯•å¤±è´¥")
        return False

def test_data_format():
    """æµ‹è¯•æ•°æ®æ ¼å¼"""
    print("\nğŸ“‹ æµ‹è¯•æ•°æ®æ ¼å¼...")
    
    # æµ‹è¯•è¾“å…¥æ ¼å¼
    test_inputs = [
        "hello world",
        "hello world hello hadoop",
        "this is a test file",
        "",  # ç©ºè¡Œ
        "   ",  # ç©ºç™½
        "word1 word2 word3 word4 word5"  # é•¿è¡Œ
    ]
    
    all_passed = True
    
    for test_input in test_inputs:
        print(f"\n  æµ‹è¯•è¾“å…¥: '{test_input}'")
        
        if not test_input.strip():
            print("  è·³è¿‡ç©ºè¾“å…¥")
            continue
        
        # æ¨¡æ‹Ÿmapperå¤„ç†
        words = test_input.split()
        mapper_lines = [f"{word}\t1" for word in words]
        
        # éªŒè¯æ ¼å¼
        for line in mapper_lines:
            if '\t' not in line:
                print(f"  âŒ æ ¼å¼é”™è¯¯: {line}")
                all_passed = False
                continue
            
            parts = line.split('\t')
            if len(parts) != 2 or parts[1] != '1':
                print(f"  âŒ æ ¼å¼é”™è¯¯: {line}")
                all_passed = False
        
        print(f"  ç”Ÿæˆ {len(mapper_lines)} è¡Œè¾“å‡º")
    
    if all_passed:
        print("âœ… æ•°æ®æ ¼å¼æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ æ•°æ®æ ¼å¼æµ‹è¯•å¤±è´¥")
    
    return all_passed

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\nğŸ“‹ æµ‹è¯•å†…å­˜ä½¿ç”¨...")
    
    # ç”Ÿæˆå¤§æ•°æ®é›†
    large_data = "hello world " * 10000  # 20000ä¸ªå•è¯
    
    print(f"æµ‹è¯•æ•°æ®å¤§å°: {len(large_data.split())} ä¸ªå•è¯")
    
    # æ¨¡æ‹Ÿå¤„ç†
    start_time = time.time()
    
    # mapperé˜¶æ®µ
    words = large_data.split()
    mapper_lines = [f"{word}\t1" for word in words]
    
    # reduceré˜¶æ®µï¼ˆæ¨¡æ‹Ÿï¼‰
    word_counts = {}
    for line in mapper_lines:
        word, count = line.split('\t')
        word_counts[word] = word_counts.get(word, 0) + 1
    
    end_time = time.time()
    
    print(f"å¤„ç†æ—¶é—´: {end_time - start_time:.3f}s")
    print(f"å†…å­˜ä½¿ç”¨: çº¦ {len(word_counts)} ä¸ªå”¯ä¸€å•è¯")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
    if len(word_counts) <= 2:  # åº”è¯¥åªæœ‰helloå’Œworldä¸¤ä¸ªå”¯ä¸€å•è¯
        print("âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("âŒ å†…å­˜ä½¿ç”¨å¼‚å¸¸")
        return False

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ“‹ æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    # æµ‹è¯•å„ç§é”™è¯¯æƒ…å†µ
    test_cases = [
        ("", "ç©ºè¾“å…¥"),
        ("   ", "ç©ºç™½è¾“å…¥"),
        ("hello\tworld", "åŒ…å«åˆ¶è¡¨ç¬¦çš„è¾“å…¥"),
        ("hello\nworld", "åŒ…å«æ¢è¡Œç¬¦çš„è¾“å…¥"),
        ("hello123 hello456", "æ•°å­—æ··åˆ"),
        ("HELLO hello Hello", "å¤§å°å†™æ··åˆ")
    ]
    
    all_passed = True
    
    for test_input, description in test_cases:
        print(f"\n  æµ‹è¯•: {description}")
        print(f"  è¾“å…¥: '{test_input}'")
        
        try:
            if not test_input.strip():
                print("  æ­£ç¡®å¤„ç†ç©ºè¾“å…¥")
                continue
            
            # æ¨¡æ‹Ÿå¤„ç†
            words = test_input.split()
            mapper_lines = [f"{word}\t1" for word in words]
            
            # æ£€æŸ¥è¾“å‡º
            print(f"  ç”Ÿæˆ {len(mapper_lines)} è¡Œè¾“å‡º")
            print("  âœ… å¤„ç†æˆåŠŸ")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {str(e)}")
            all_passed = False
    
    if all_passed:
        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥")
    
    return all_passed

def generate_java_test_report():
    """ç”ŸæˆJavaæµ‹è¯•æŠ¥å‘Š"""
    print("\nğŸ“Š ç”ŸæˆJavaæµ‹è¯•æŠ¥å‘Š...")
    
    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "test_results": {},
        "summary": {}
    }
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("compilation", test_java_compilation),
        ("mapper_logic", test_mapper_logic),
        ("reducer_logic", test_reducer_logic),
        ("data_format", test_data_format),
        ("memory_usage", test_memory_usage),
        ("error_handling", test_error_handling)
    ]
    
    total_passed = 0
    total_tests = len(tests)
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            report["test_results"][test_name] = "PASSED" if result else "FAILED"
            if result:
                total_passed += 1
        except Exception as e:
            report["test_results"][test_name] = f"ERROR: {str(e)}"
            print(f"âŒ {test_name} æµ‹è¯•å‡ºé”™: {str(e)}")
    
    # ç”Ÿæˆæ‘˜è¦
    report["summary"] = {
        "total_tests": total_tests,
        "passed": total_passed,
        "failed": total_tests - total_passed,
        "success_rate": f"{(total_passed/total_tests)*100:.1f}%"
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "java_test_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nJavaæµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"\næµ‹è¯•æ‘˜è¦:")
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡: {total_passed}")
    print(f"å¤±è´¥: {total_tests - total_passed}")
    print(f"æˆåŠŸç‡: {(total_passed/total_tests)*100:.1f}%")
    
    return total_passed == total_tests

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Java MapReduce æœ¬åœ°Mockæµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    create_test_java_files()
    
    # è¿è¡Œæµ‹è¯•
    success = generate_java_test_report()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰Javaæµ‹è¯•é€šè¿‡ï¼å¯ä»¥å®‰å…¨éƒ¨ç½²åˆ°Dockerç¯å¢ƒ")
        print("ğŸ’¡ å»ºè®®: åœ¨Dockerç¯å¢ƒä¸­ä½¿ç”¨å°æ•°æ®é›†è¿›è¡Œæœ€ç»ˆéªŒè¯")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·å…ˆä¿®å¤é—®é¢˜å†éƒ¨ç½²")
        print("ğŸ”§ æç¤º: æ£€æŸ¥æµ‹è¯•æŠ¥å‘Šè·å–è¯¦ç»†ä¿¡æ¯")
    
    return success

if __name__ == '__main__':
    import sys
    success = main()
    sys.exit(0 if success else 1)