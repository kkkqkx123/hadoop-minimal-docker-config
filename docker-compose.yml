version: "3.9"

# Hadoop HDFS-only 配置
# 仅启动HDFS服务，禁用YARN和MapReduce以节省资源
# 与Spark Standalone模式配合使用

services:
  namenode:
    image: hadoop:optimized
    container_name: namenode
    hostname: namenode
    deploy:
      resources:
        limits:
          memory: 1.2G
          cpus: '1.0'
        reservations:
          memory: 800M
          cpus: '0.5'
    environment:
      - HADOOP_ROLE=namenode
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - HDFS_SECONDARYNAMENODE_USER=root
      - SHELL=/bin/bash
    ports:
      - "9870:9870"   # NameNode Web UI
      - "9000:9000"   # HDFS NN RPC
      - "22:22"       # SSH（可选）
    volumes:
      - namenode:/hadoop/dfs/namenode
      - ./conf:/opt/hadoop/etc/hadoop:ro
    networks:
      - hadoop
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    command: >
      bash -c "
        hdfs --daemon start namenode &&
        tail -f /dev/null
      "
    restart: unless-stopped

  datanode:
    image: hadoop:optimized
    container_name: datanode
    hostname: datanode
    deploy:
      resources:
        limits:
          memory: 800M
          cpus: '0.8'
        reservations:
          memory: 400M
          cpus: '0.3'
    environment:
      - HADOOP_ROLE=datanode
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - SHELL=/bin/bash
    ports:
      - "9864:9864"   # DataNode Web UI
    volumes:
      - datanode:/hadoop/dfs/datanode
      - ./conf:/opt/hadoop/etc/hadoop:ro
    networks:
      - hadoop
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9864"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    command: >
      bash -c "
        # 等待NameNode启动
        sleep 30 &&
        hdfs --daemon start datanode &&
        tail -f /dev/null
      "
    restart: unless-stopped

volumes:
  namenode:
  datanode:

networks:
  hadoop:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1450