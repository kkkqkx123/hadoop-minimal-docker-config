# Hadoop Docker 快速开始指南

## 🚀 环境验证

首先运行测试脚本验证环境是否正常工作：

```bash
# 进入WSL环境
cd /home/docker-compose/hadoop

# 运行完整测试
./test-scripts/test-custom-code.sh

# 或者只测试特定功能
./test-scripts/test-custom-code.sh --hdfs-only    # 只测试HDFS
./test-scripts/test-custom-code.sh --python-only  # 只测试Python Streaming
./test-scripts/test-custom-code.sh --java-only    # 只测试Java MapReduce
```

## 📝 执行自定义代码的3种方式

### 方式1：Java MapReduce程序

**步骤：**
1. 编写Java代码（参考 `docs/coding/在hadoop-docker上执行自定义代码指南.md`）
2. 编译打包成JAR文件
3. 将JAR文件复制到master容器：`docker cp your-program.jar hadoop-master:/tmp/`
4. 执行：`docker-compose exec master hadoop jar /tmp/your-program.jar [参数]`

**示例：**
```bash
# 使用内置的PI计算示例
docker-compose exec master hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar pi 2 5
```

### 方式2：Python MapReduce（Hadoop Streaming）

**步骤：**
1. 创建mapper和reducer Python脚本
2. 将脚本复制到master容器
3. 准备输入数据并上传到HDFS
4. 使用Hadoop Streaming执行

**快速示例：**
```bash
# 生成示例脚本
cd /home/docker-compose/hadoop/examples/wordcount
python3 generate_wordcount.py

# 复制脚本到容器
docker cp mapper.py hadoop-master:/tmp/
docker cp reducer.py hadoop-master:/tmp/

# 创建测试数据
echo "hello world hello hadoop python streaming is awesome" | docker-compose exec -T master tee /tmp/input.txt

# 上传到HDFS
docker-compose exec master hdfs dfs -mkdir -p /wordcount/input
docker-compose exec master hdfs dfs -put /tmp/input.txt /wordcount/input/

# 执行MapReduce
docker-compose exec master hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \
    -files /tmp/mapper.py,/tmp/reducer.py \
    -mapper 'python3 /tmp/mapper.py' \
    -reducer 'python3 /tmp/reducer.py' \
    -input /wordcount/input \
    -output /wordcount/output

# 查看结果
docker-compose exec master hdfs dfs -cat /wordcount/output/part-*
```

### 方式3：Shell脚本批量处理

**步骤：**
1. 编写Shell脚本处理数据
2. 将脚本和数据复制到容器
3. 使用HDFS存储输入输出

**示例：**
```bash
# 创建处理脚本
cat > /tmp/process.sh << 'EOF'
#!/bin/bash
while IFS= read -r line; do
    echo "Processed: $line" | wc -w
done
EOF

# 复制到容器并执行
docker cp /tmp/process.sh hadoop-master:/tmp/
docker-compose exec master chmod +x /tmp/process.sh

# 处理数据
docker-compose exec master hdfs dfs -cat /your/input/path/* | \
    docker-compose exec -T master /tmp/process.sh
```

## 📊 监控和调试

### 查看作业状态
```bash
# 查看正在运行的作业
docker-compose exec master yarn application -list

# 查看作业详情
docker-compose exec master yarn application -status <application_id>

# 查看作业日志
docker-compose exec master yarn logs -applicationId <application_id>
```

### 查看HDFS状态
```bash
# 查看HDFS状态
docker-compose exec master hdfs dfsadmin -report

# 查看文件系统
docker-compose exec master hdfs dfs -ls /

# 查看文件内容
docker-compose exec master hdfs dfs -cat /path/to/file
```

### 查看服务日志
```bash
# 查看ResourceManager日志
docker-compose logs --tail=50 master | grep ResourceManager

# 查看NodeManager日志
docker-compose logs --tail=50 worker1 | grep NodeManager
```

## ⚡ 性能调优建议

### 资源配置
- Map任务内存：`mapreduce.map.memory.mb=512`
- Reduce任务内存：`mapreduce.reduce.memory.mb=512`
- JVM堆大小：`mapreduce.map.java.opts=-Xmx384m`

### 并行度设置
- Map任务数：`mapreduce.job.maps=2`
- Reduce任务数：`mapreduce.job.reduces=1`

### 数据本地化
- 尽量将输入数据分散存储在不同节点
- 使用适当的块大小（默认128MB）

## 🛠️ 常见问题解决

### 1. 作业执行失败
- 检查服务状态：`docker-compose exec master jps`
- 检查HDFS空间：`docker-compose exec master hdfs dfs -df -h`
- 查看详细日志：`docker-compose exec master yarn logs -applicationId <id>`

### 2. 内存不足
- 减少map/reduce任务数
- 降低内存配置
- 使用更小的数据集测试

### 3. 权限问题
- 确保HDFS目录存在：`docker-compose exec master hdfs dfs -mkdir -p /user/root`
- 检查文件权限：`docker-compose exec master hdfs dfs -ls /`

## 📚 更多资源

- 详细指南：`docs/coding/在hadoop-docker上执行自定义代码指南.md`
- 测试脚本：`test-scripts/test-custom-code.sh`
- 示例代码：`examples/wordcount/`

## 🎯 下一步

1. 运行测试脚本验证环境
2. 尝试Python Streaming示例
3. 编写自己的MapReduce程序
4. 探索更多Hadoop生态工具（Hive、Pig等）